import 'package:cloud_firestore/cloud_firestore.dart';
import 'dart:async';

class CleanupService {
  static final FirebaseFirestore _firestore = FirebaseFirestore.instance;
  static const String _collection = 'reports';
  static Timer? _cleanupTimer;

  /// ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö‡∏•‡∏ö‡πÇ‡∏û‡∏™‡∏ï‡πå‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥
  static void startAutoCleanup() {
    print('üßπ Starting auto cleanup service...');

    // ‡∏£‡∏±‡∏ô‡∏ó‡∏±‡∏ô‡∏ó‡∏µ‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÅ‡∏£‡∏Å
    _performCleanup();

    // ‡∏ï‡∏±‡πâ‡∏á‡πÉ‡∏´‡πâ‡∏£‡∏±‡∏ô‡∏ó‡∏∏‡∏Å 1 ‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á
    _cleanupTimer = Timer.periodic(const Duration(hours: 1), (timer) {
      _performCleanup();
    });

    print('üßπ Auto cleanup service started - runs every 1 hour');
  }

  /// ‡∏´‡∏¢‡∏∏‡∏î‡∏£‡∏∞‡∏ö‡∏ö‡∏•‡∏ö‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥
  static void stopAutoCleanup() {
    _cleanupTimer?.cancel();
    _cleanupTimer = null;
    print('üßπ Auto cleanup service stopped');
  }

  /// ‡∏•‡∏ö‡πÇ‡∏û‡∏™‡∏ï‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡πà‡∏≤‡∏Å‡∏ß‡πà‡∏≤ 48 ‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á (‡πÉ‡∏ä‡πâ Batch ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Firebase ‡∏ü‡∏£‡∏µ)
  static Future<void> _performCleanup() async {
    try {
      final cutoffTime = DateTime.now().subtract(const Duration(hours: 48));
      final cutoffTimestamp = Timestamp.fromDate(cutoffTime);

      print('üßπ Starting cleanup for posts older than: $cutoffTime');

      // ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÇ‡∏û‡∏™‡∏ï‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡πà‡∏≤‡∏Å‡∏ß‡πà‡∏≤ 48 ‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á (‡∏à‡∏≥‡∏Å‡∏±‡∏î 20 ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ï‡πà‡∏≠‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏∞‡∏´‡∏¢‡∏±‡∏î quota)
      final oldPostsQuery = await _firestore
          .collection(_collection)
          .where('timestamp', isLessThan: cutoffTimestamp)
          .limit(20) // ‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏∞‡∏´‡∏¢‡∏±‡∏î Firebase quota
          .get();

      if (oldPostsQuery.docs.isEmpty) {
        print('üßπ No old posts found to cleanup');
        return;
      }

      print('üßπ Found ${oldPostsQuery.docs.length} old posts to delete (batch)');

      // ‡πÉ‡∏ä‡πâ Batch Write ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡∏î‡∏µ‡∏Å‡∏ß‡πà‡∏≤
      final batch = _firestore.batch();
      int deletedCount = 0;

      for (final doc in oldPostsQuery.docs) {
        try {
          final data = doc.data() as Map<String, dynamic>?;
          final timestamp = data?['timestamp'] as Timestamp?;
          final category = data?['category'] ?? 'unknown';

          print(
              'üóëÔ∏è Adding to batch delete: ${doc.id} - Category: $category, Age: ${timestamp?.toDate()}');

          // ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡∏•‡∏ö‡πÇ‡∏û‡∏™‡∏ï‡πå‡πÄ‡∏Ç‡πâ‡∏≤ batch
          batch.delete(doc.reference);
          deletedCount++;

          // ‡∏•‡∏ö comments ‡πÅ‡∏ö‡∏ö batch ‡∏î‡πâ‡∏ß‡∏¢ (‡πÅ‡∏ï‡πà‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏à‡∏≥‡∏ô‡∏ß‡∏ô)
          await _addCommentDeletionsToBatch(batch, doc.id);

        } catch (e) {
          print('‚ùå Error adding post ${doc.id} to batch: $e');
        }
      }

      // Execute batch write (‡∏õ‡∏£‡∏∞‡∏´‡∏¢‡∏±‡∏î write operations)
      if (deletedCount > 0) {
        await batch.commit();
        print('üßπ Batch cleanup completed - Deleted $deletedCount posts');
      }

    } catch (e) {
      print('‚ùå Error during cleanup: $e');
    }
  }

  /// ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡∏•‡∏ö comments ‡πÄ‡∏Ç‡πâ‡∏≤ batch (‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏∞‡∏´‡∏¢‡∏±‡∏î quota)
  static Future<void> _addCommentDeletionsToBatch(WriteBatch batch, String postId) async {
    try {
      // ‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏Å‡∏≤‡∏£ read comments ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏∞‡∏´‡∏¢‡∏±‡∏î Firebase quota
      final commentsQuery = await _firestore
          .collection(_collection)
          .doc(postId)
          .collection('comments')
          .limit(10) // ‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏à‡∏≥‡∏ô‡∏ß‡∏ô comments ‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏•‡∏ö‡∏ï‡πà‡∏≠‡∏Ñ‡∏£‡∏±‡πâ‡∏á
          .get();

      if (commentsQuery.docs.isNotEmpty) {
        print(
            'üóëÔ∏è Adding ${commentsQuery.docs.length} comments to batch for post $postId');

        for (final commentDoc in commentsQuery.docs) {
          batch.delete(commentDoc.reference);
        }
      }
    } catch (e) {
      print('‚ùå Error adding comments to batch for post $postId: $e');
    }
  }
    } catch (e) {
      print('‚ùå Error deleting comments for post $postId: $e');
    }
  }

  /// ‡∏•‡∏ö‡πÇ‡∏û‡∏™‡∏ï‡πå‡πÄ‡∏Å‡πà‡∏≤‡∏î‡πâ‡∏ß‡∏¢‡∏ï‡∏ô‡πÄ‡∏≠‡∏á (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ó‡∏î‡∏™‡∏≠‡∏ö)
  static Future<int> manualCleanup() async {
    print('üßπ Starting manual cleanup...');
    await _performCleanup();

    // ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÇ‡∏û‡∏™‡∏ï‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏•‡∏∑‡∏≠
    final remainingPosts = await _firestore.collection(_collection).get();

    final freshPosts = await _firestore
        .collection(_collection)
        .where('timestamp',
            isGreaterThan: Timestamp.fromDate(
                DateTime.now().subtract(const Duration(hours: 48))))
        .get();

    print('üßπ Manual cleanup completed');
    print('üìä Total posts: ${remainingPosts.docs.length}');
    print('üìä Fresh posts (48h): ${freshPosts.docs.length}');

    return freshPosts.docs.length;
  }

  /// ‡∏î‡∏π‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡πÇ‡∏û‡∏™‡∏ï‡πå
  static Future<Map<String, int>> getPostStatistics() async {
    try {
      final now = DateTime.now();
      final fortyEightHoursAgo = now.subtract(const Duration(hours: 48));

      // ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÇ‡∏û‡∏™‡∏ï‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
      final totalQuery = await _firestore.collection(_collection).get();

      // ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÇ‡∏û‡∏™‡∏ï‡πå‡∏™‡∏î‡πÉ‡∏´‡∏°‡πà (48 ‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á)
      final freshQuery = await _firestore
          .collection(_collection)
          .where('timestamp',
              isGreaterThan: Timestamp.fromDate(fortyEightHoursAgo))
          .get();

      return {
        'total': totalQuery.docs.length,
        'fresh': freshQuery.docs.length,
        'old': totalQuery.docs.length - freshQuery.docs.length,
      };
    } catch (e) {
      print('‚ùå Error getting statistics: $e');
      return {'total': 0, 'fresh': 0, 'old': 0};
    }
  }
}
